{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351c1fdb-9d87-4382-9496-1b3917036072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f45baf-7c79-463a-a4ae-de6aac3043ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6a9b32-37bc-4e48-89a8-fa6bb1236817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2447af-7a3b-4bbe-b77d-b75ef6a2d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'D:\\Kaggle\\digit-recognizer\\train.csv')\n",
    "test_df = pd.read_csv(r'D:\\Kaggle\\digit-recognizer\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e5948d-876f-43c7-bc40-7a0bbc6ea565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_operation(row, direction):\n",
    "    label = row.iloc[0]\n",
    "    image = row.iloc[1:].values.reshape((28,28))\n",
    "    \n",
    "    if direction == 'left':\n",
    "        shifted_img = shift(image, shift=[0, -1], mode='constant', cval=0)\n",
    "    elif direction == 'right':\n",
    "        shifted_img = shift(image, shift=[0, 1], mode='constant', cval=0)\n",
    "    elif direction == 'top':\n",
    "        shifted_img = shift(image, shift=[-1, 0], mode='constant', cval=0)\n",
    "    elif direction == 'bottom':\n",
    "        shifted_img = shift(image, shift=[1, 0], mode='constant', cval=0)\n",
    "    \n",
    "    \n",
    "    return [label]+shifted_img.flatten().tolist()\n",
    "\n",
    "# Apply the function row-wise for different shifts\n",
    "df_left = train_df.apply(lambda row: row_operation(row, 'left'), axis=1,result_type='expand')\n",
    "df_right = train_df.apply(lambda row: row_operation(row, 'right'), axis=1,result_type='expand')\n",
    "df_top = train_df.apply(lambda row: row_operation(row, 'top'), axis=1,result_type='expand')\n",
    "df_bottom = train_df.apply(lambda row: row_operation(row, 'bottom'), axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79a36d3-9f75-4565-acdc-6cd2f773b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left.columns= df_right.columns= df_top.columns= df_bottom.columns = train_df.columns\n",
    "\n",
    "train_df = pd.concat([train_df,df_left,df_right,df_bottom,df_top],axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5413a50-698e-446d-b721-fb2a62b5f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['label'],axis=1)\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc8c7d5-76f9-4fba-ab8b-f1f07b66b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "test_df = test_df / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4fdc97-73c6-4ad2-8573-f66585448d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484f4071-94a0-4e70-b137-39b50c6a58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.long)\n",
    "X_test = torch.tensor(test_df.values,dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d91d3dd-9fea-4332-acce-93a3fc828d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([168000, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad3fb27-40d3-495b-82b9-29ad3d1d6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dff6f7b-e7ce-4b57-8ab8-05bf9ffb5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60297e00-9300-4475-bc60-2bc8de50c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd13075-264b-49e3-877e-7eae3a530203",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bbd6a76-b144-4157-8cbd-ca518982f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataLoader in module torch.utils.data.dataloader object:\n",
      "\n",
      "class DataLoader(typing.Generic)\n",
      " |  DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |\n",
      " |  Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      " |\n",
      " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      " |  iterable-style datasets with single- or multi-process loading, customizing\n",
      " |  loading order and optional automatic batching (collation) and memory pinning.\n",
      " |\n",
      " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
      " |\n",
      " |  Args:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
      " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      " |          returns a batch of indices at a time. Mutually exclusive with\n",
      " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      " |          and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. ``0`` means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (Callable, optional): merges a list of samples to form a\n",
      " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
      " |          map-style dataset.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      " |          into device/CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |      multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      " |          ``None``, the default `multiprocessing context`_ of your operating system will\n",
      " |          be used. (default: ``None``)\n",
      " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
      " |          ``base_seed`` for workers. (default: ``None``)\n",
      " |      prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      " |          in advance by each worker. ``2`` means there will be a total of\n",
      " |          2 * num_workers batches prefetched across all workers. (default value depends\n",
      " |          on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      " |          Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      " |      persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      " |          the worker processes after a dataset has been consumed once. This allows to\n",
      " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      " |      pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      " |          ``True``.\n",
      " |\n",
      " |\n",
      " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
      " |               :ref:`multiprocessing-best-practices` on more details related\n",
      " |               to multiprocessing in PyTorch.\n",
      " |\n",
      " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
      " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
      " |               loading to avoid duplicate data.\n",
      " |\n",
      " |               However, if sharding results in multiple workers having incomplete last batches,\n",
      " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      " |               cases in general.\n",
      " |\n",
      " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
      " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
      " |               `Multi-process data loading`_.\n",
      " |\n",
      " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
      " |\n",
      " |  .. _multiprocessing context:\n",
      " |      https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      DataLoader\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
      " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
      " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
      " |\n",
      " |  __len__(self) -> int\n",
      " |\n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  check_worker_number_rationality(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  multiprocessing_context\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_iterator': typing.Optional[ForwardRef('_BaseDataL...\n",
      " |\n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |\n",
      " |  __parameters__ = (+T_co,)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6708acc-6309-4510-b87f-85383573ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_NN(nn.Module):\n",
    "    def __init__(self,input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,out_features=output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        return self.layer_stack(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb7d6de-1e65-410a-9952-9e6db97d9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "model = MNIST_NN(784,32,classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def62a09-b95e-4b46-9f42-518835b2f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_mode(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, accuracy_fn, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch, (X, y) in enumerate(data_loader):                \n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += accuracy_fn(y_pred.argmax(dim=1), y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "    train_loss /= len(data_loader)\n",
    "    train_accuracy /= len(data_loader)\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def test_mode(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module, accuracy_fn, optimizer: torch.optim.Optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            test_pred = model(X)\n",
    "            test_loss += loss_fn(test_pred, y).item()\n",
    "            test_accuracy += accuracy_fn(test_pred.argmax(dim=1), y)\n",
    "            if batch % 400 == 0:\n",
    "                print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "        test_loss /= len(data_loader)\n",
    "        test_accuracy /= len(data_loader)\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2ec7bd-3668-4b8e-9bb8-97e3247c7d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e3d3d324fc44f39df5739327d92ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.53249 | Train accuracy: 84.34108\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.28007 | Train accuracy: 91.74820\n",
      "Epoch: 1\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.21461 | Train accuracy: 93.67741\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.18684 | Train accuracy: 94.43152\n",
      "Epoch: 2\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.15906 | Train accuracy: 95.26609\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.16856 | Train accuracy: 94.91594\n",
      "Epoch: 3\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.13329 | Train accuracy: 96.02770\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.14278 | Train accuracy: 95.83492\n",
      "Epoch: 4\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.11716 | Train accuracy: 96.43172\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.12115 | Train accuracy: 96.42382\n",
      "Epoch: 5\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.10484 | Train accuracy: 96.77801\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.12040 | Train accuracy: 96.41907\n",
      "Epoch: 6\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.09745 | Train accuracy: 97.01602\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.11260 | Train accuracy: 96.76577\n",
      "Epoch: 7\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.09061 | Train accuracy: 97.17251\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10819 | Train accuracy: 96.81801\n",
      "Epoch: 8\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.08548 | Train accuracy: 97.36469\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.11012 | Train accuracy: 96.78239\n",
      "Epoch: 9\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.08131 | Train accuracy: 97.48429\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.11265 | Train accuracy: 96.63516\n",
      "Epoch: 10\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.07733 | Train accuracy: 97.61162\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10455 | Train accuracy: 96.87975\n",
      "Epoch: 11\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.07368 | Train accuracy: 97.67886\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10550 | Train accuracy: 96.97473\n",
      "Epoch: 12\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.07132 | Train accuracy: 97.74729\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.09558 | Train accuracy: 97.15046\n",
      "Epoch: 13\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.06801 | Train accuracy: 97.87938\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.09823 | Train accuracy: 97.12908\n",
      "Epoch: 14\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.06600 | Train accuracy: 97.92044\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10032 | Train accuracy: 97.03885\n",
      "Epoch: 15\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.06389 | Train accuracy: 97.97458\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.11477 | Train accuracy: 96.66603\n",
      "Epoch: 16\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.06210 | Train accuracy: 98.01564\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10373 | Train accuracy: 97.07684\n",
      "Epoch: 17\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.06023 | Train accuracy: 98.06919\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10763 | Train accuracy: 96.79189\n",
      "Epoch: 18\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.05857 | Train accuracy: 98.14297\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.10219 | Train accuracy: 97.03885\n",
      "Epoch: 19\n",
      "---------\n",
      "Looked at 0/168000 samples\n",
      "Looked at 51200/168000 samples\n",
      "Looked at 102400/168000 samples\n",
      "Looked at 153600/168000 samples\n",
      "\n",
      "Train loss: 0.05669 | Train accuracy: 98.18581\n",
      "Looked at 0/42000 samples\n",
      "\n",
      "Train loss: 0.09388 | Train accuracy: 97.37130\n",
      "Train time on cpu: 173.408 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 20\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_loss, train_accuracy = train_mode(model,train_dataloader,loss_fn,accuracy_fn,optimizer)\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Train accuracy: {train_accuracy:.5f}\")\n",
    "    test_loss, test_accuracy = test_mode(model,val_dataloader,loss_fn,accuracy_fn,optimizer)\n",
    "    print(f\"\\nTrain loss: {test_loss:.5f} | Train accuracy: {test_accuracy:.5f}\")\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(model.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38b1da18-3dd0-42f2-a8f7-871acedf597b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'MNIST_NN',\n",
       " 'model_loss': 0.09371914714574814,\n",
       " 'model_acc': 97.3879179331307}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn):\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in data_loader:\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred,y)\n",
    "            acc += accuracy_fn(y,y_pred.argmax(dim=1))\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "simple_results = eval_model(model=model, data_loader=val_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn\n",
    ")\n",
    "simple_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b562f53f-6802-49cc-94e1-1db62c777b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X in data_loader:\n",
    "            y_pred = model(X[0])\n",
    "            predictions.append(y_pred.argmax(dim=1).numpy())\n",
    "\n",
    "    # Concatenate all batch predictions\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    return {\"model_name\": model.__class__.__name__,  # Only works when model was created with a class\n",
    "            \"predictions\": predictions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43309eb7-24f8-42b2-bf87-f3b08ab91568",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = eval_model(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7985240c-963d-43c2-879c-32e80ec4dde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72b4f635-fb62-43ee-b2b1-ab60960c0b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'random_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ImageId': range(1, len(output['predictions']) + 1),\n",
    "    'Label': output['predictions']\n",
    "})\n",
    "\n",
    "submission.to_csv(r'D:\\Kaggle\\digit-recognizer\\nn_submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'random_submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9436c881-ef5e-42eb-bf24-a5a43165f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for x in test_dataloader:\n",
    "    print(x[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dabc2c5-0890-4c2f-987c-138600c3377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['predictions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba3db9b-588a-4a00-b3a7-dcb705b4d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ade3d-165f-4c33-a9d1-63faac2c443a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
