{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51a534a-2a44-4954-961a-0c37db2a320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfde108-590e-4fe2-ae46-32d85db26b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text_lemma_spacy(text):\n",
    "    doc = nlp(text.lower()) \n",
    "    lemmatized_words = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
    "    return ' '.join(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8f4c59-fc50-47db-aa76-682a7109f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    return ' '.join([stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbc66f2-6378-429b-971a-41317e77d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"D:\\elggak\\kaggle\\Tweet Disaster Competition\\nlp-getting-started\\train.csv\")\n",
    "test_df = pd.read_csv(r\"D:\\elggak\\kaggle\\Tweet Disaster Competition\\nlp-getting-started\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e28a093-b419-46eb-a352-960645ee1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pattern = r'\\b(\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}|(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2},?\\s\\d{4})\\b'\n",
    "time_pattern = r'\\b((0?[1-9]|1[0-2]):[0-5]\\d\\s?(AM|PM)|([01]\\d|2[0-3]):[0-5]\\d(:[0-5]\\d)?)\\b'\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'bin laden', 'Binladen', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", 'http', text, flags=re.MULTILINE)  \n",
    "    #text = re.sub(r'\\@\\w+|\\#','', text)  \n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\b(?<!breaking)news\\b|\\b(?<!breaking)\\w*news\\w*\\b', 'news', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text\n",
    "\n",
    "# train_df['text'] = train_df['text'].apply(lambda x: re.sub(date_pattern, 'DATETIME', x))\n",
    "# train_df['text'] = train_df['text'].apply(lambda x: re.sub(time_pattern, 'DATETIME', x))\n",
    "# test_df['text'] = test_df['text'].apply(lambda x: re.sub(date_pattern, 'DATETIME', x))\n",
    "# test_df['text'] = test_df['text'].apply(lambda x: re.sub(time_pattern, 'DATETIME', x))\n",
    "train_df['text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text)\n",
    "train_df['text'] = train_df['text'].apply(preprocess_text_lemma_spacy)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text_lemma_spacy)\n",
    "train_df['text'] = train_df['text'].apply(stemming)\n",
    "test_df['text'] = test_df['text'].apply(stemming)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb9bd0b-7f73-4775-8aa4-cf94a4b11baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_id = train_df['id']\n",
    "test_df_id = test_df['id']\n",
    "X = train_df['text']\n",
    "y = train_df['target']\n",
    "X_test = test_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944cff03-e91f-4a46-a143-d8dbcc692158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613,), (3263,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b19f43-f813-4f25-acdf-450832f18caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093bbfab-96a4-4ed9-a915-58f490d5b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X).toarray() \n",
    "y = y.values\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZES, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZES,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acbfa75-e8ab-4692-aa85-f40f1957778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27c9155-e573-45c1-aa83-a32290e4a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed6db1b-5b32-4c7d-ae8c-7ba68c07906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d60434-4645-4b9c-bcb9-de23ac42b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDisasterModel(nn.Module):\n",
    "    def __init__(self,input_shape,hidden_units,out_shape):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,out_features=out_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        return self.layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c292b425-92ab-4ce0-aeea-d5de5399b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_model = TweetDisasterModel(X_train.shape[1],8,1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(tweet_model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541c8af4-7b1e-4782-aba0-cb28892b4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(all_labels, all_preds):\n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy_score(all_labels, all_preds)),\n",
    "        'confusion_matrix': confusion_matrix(all_labels, all_preds),  # It's fine to leave the matrix as-is\n",
    "        'precision': float(precision_score(all_labels, all_preds)),\n",
    "        'recall': float(recall_score(all_labels, all_preds)),\n",
    "        'f1': float(f1_score(all_labels, all_preds)),\n",
    "        'macro_precision': float(precision_score(all_labels, all_preds, average='macro')),\n",
    "        'macro_recall': float(recall_score(all_labels, all_preds, average='macro')),\n",
    "        'macro_f1': float(f1_score(all_labels, all_preds, average='macro')),\n",
    "        'micro_precision': float(precision_score(all_labels, all_preds, average='micro')),\n",
    "        'micro_recall': float(recall_score(all_labels, all_preds, average='micro')),\n",
    "        'micro_f1': float(f1_score(all_labels, all_preds, average='micro'))\n",
    "    }\n",
    "    \n",
    "    return metrics, classification_report(all_labels, all_preds, target_names=['ham', 'spam'],digits = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc8c6e0-9fe0-4537-8269-83714078e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model: torch.nn.Module,data_loader: torch.utils.data.DataLoader, loss_fn:torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "        y_preds = model(X)\n",
    "        loss = loss_fn(y_preds, y.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.sigmoid(y_preds).round()  # Apply sigmoid and threshold at 0.5\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        # running_accuracy +=\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "    train_loss = running_loss/len(data_loader)\n",
    "    \n",
    "    return train_loss, calculate_metrics(all_labels,all_preds)\n",
    "\n",
    "def test_mode(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "        y_preds = model(X)\n",
    "        loss = loss_fn(y_preds, y.unsqueeze(1))\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.sigmoid(y_preds).round()  # Apply sigmoid and threshold at 0.5\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        if batch % 400 == 0:\n",
    "                print(f\"Looked at {batch * len(X)}/{len(data_loader.dataset)} samples\")\n",
    "    test_loss = running_loss/len(data_loader)\n",
    "    \n",
    "    return test_loss, calculate_metrics(all_labels,all_preds)\n",
    "\n",
    "def predict_on_test_set(model: torch.nn.Module, test_loader: torch.utils.data.DataLoader):\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        for batch, X in enumerate(test_loader):\n",
    "        \n",
    "            y_preds = model(X[0])\n",
    "            preds = torch.sigmoid(y_preds).round()  \n",
    "            all_preds.extend(preds.detach().cpu().numpy()) \n",
    "\n",
    "    return all_preds \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd47258-414b-44af-85ac-c5405c58a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc452b8258648d8b8f8c0315cddfbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "---------\n",
      "Looked at 0/6090 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.67853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.569458  1.000000  0.725675      3468\n",
      "        spam   0.000000  0.000000  0.000000      2622\n",
      "\n",
      "    accuracy                       0.569458      6090\n",
      "   macro avg   0.284729  0.500000  0.362837      6090\n",
      "weighted avg   0.324283  0.569458  0.413241      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.66794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.573867  1.000000  0.729245       874\n",
      "        spam   0.000000  0.000000  0.000000       649\n",
      "\n",
      "    accuracy                       0.573867      1523\n",
      "   macro avg   0.286934  0.500000  0.364622      1523\n",
      "weighted avg   0.329324  0.573867  0.418490      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 1\n",
      "---------\n",
      "Looked at 0/6090 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.64933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.597622  1.000000  0.748139      3468\n",
      "        spam   1.000000  0.109458  0.197319      2622\n",
      "\n",
      "    accuracy                       0.616585      6090\n",
      "   macro avg   0.798811  0.554729  0.472729      6090\n",
      "weighted avg   0.770863  0.616585  0.510988      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.64171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.625987  0.997712  0.769299       874\n",
      "        spam   0.984615  0.197227  0.328626       649\n",
      "\n",
      "    accuracy                       0.656599      1523\n",
      "   macro avg   0.805301  0.597469  0.548963      1523\n",
      "weighted avg   0.778810  0.656599  0.581514      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 2\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.60989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.671714  0.997693  0.802877      3468\n",
      "        spam   0.991480  0.355072  0.522887      2622\n",
      "\n",
      "    accuracy                       0.721018      6090\n",
      "   macro avg   0.831597  0.676383  0.662882      6090\n",
      "weighted avg   0.809387  0.721018  0.682330      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.61031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.689189  0.991991  0.813321       874\n",
      "        spam   0.973585  0.397535  0.564551       649\n",
      "\n",
      "    accuracy                       0.738674      1523\n",
      "   macro avg   0.831387  0.694763  0.688936      1523\n",
      "weighted avg   0.810379  0.738674  0.707312      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 3\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.56354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.741077  0.987889  0.846867      3468\n",
      "        spam   0.971370  0.543478  0.696992      2622\n",
      "\n",
      "    accuracy                       0.796552      6090\n",
      "   macro avg   0.856224  0.765684  0.771929      6090\n",
      "weighted avg   0.840228  0.796552  0.782339      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.57779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.734144  0.966819  0.834568       874\n",
      "        spam   0.922043  0.528505  0.671890       649\n",
      "\n",
      "    accuracy                       0.780039      1523\n",
      "   macro avg   0.828094  0.747662  0.753229      1523\n",
      "weighted avg   0.814214  0.780039  0.765246      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 4\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.51614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.781322  0.981834  0.870176      3468\n",
      "        spam   0.963626  0.636537  0.766651      2622\n",
      "\n",
      "    accuracy                       0.833169      6090\n",
      "   macro avg   0.872474  0.809185  0.818414      6090\n",
      "weighted avg   0.859811  0.833169  0.825604      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.54705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.759669  0.943936  0.841837       874\n",
      "        spam   0.887872  0.597843  0.714549       649\n",
      "\n",
      "    accuracy                       0.796454      1523\n",
      "   macro avg   0.823770  0.770889  0.778193      1523\n",
      "weighted avg   0.814300  0.796454  0.787595      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 5\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.47146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.818779  0.970588  0.888244      3468\n",
      "        spam   0.948459  0.715866  0.815910      2622\n",
      "\n",
      "    accuracy                       0.860920      6090\n",
      "   macro avg   0.883619  0.843227  0.852077      6090\n",
      "weighted avg   0.874612  0.860920  0.857101      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.52160\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.769158  0.930206  0.842051       874\n",
      "        spam   0.869099  0.624037  0.726457       649\n",
      "\n",
      "    accuracy                       0.799737      1523\n",
      "   macro avg   0.819128  0.777121  0.784254      1523\n",
      "weighted avg   0.811746  0.799737  0.792793      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 6\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.43090\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.835121  0.965398  0.895546      3468\n",
      "        spam   0.942335  0.747902  0.833936      2622\n",
      "\n",
      "    accuracy                       0.871757      6090\n",
      "   macro avg   0.888728  0.856650  0.864741      6090\n",
      "weighted avg   0.881281  0.871757  0.869020      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.50104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.780039  0.921053  0.844701       874\n",
      "        spam   0.859470  0.650231  0.740351       649\n",
      "\n",
      "    accuracy                       0.805647      1523\n",
      "   macro avg   0.819755  0.785642  0.792526      1523\n",
      "weighted avg   0.813887  0.805647  0.800234      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 7\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.39727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.853602  0.963379  0.905175      3468\n",
      "        spam   0.941636  0.781465  0.854106      2622\n",
      "\n",
      "    accuracy                       0.885057      6090\n",
      "   macro avg   0.897619  0.872422  0.879640      6090\n",
      "weighted avg   0.891505  0.885057  0.883187      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.48606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.789526  0.914188  0.847296       874\n",
      "        spam   0.853229  0.671803  0.751724       649\n",
      "\n",
      "    accuracy                       0.810900      1523\n",
      "   macro avg   0.821377  0.792995  0.799510      1523\n",
      "weighted avg   0.816672  0.810900  0.806570      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 8\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.36675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.868852  0.962803  0.913418      3468\n",
      "        spam   0.942590  0.807780  0.869994      2622\n",
      "\n",
      "    accuracy                       0.896059      6090\n",
      "   macro avg   0.905721  0.885292  0.891706      6090\n",
      "weighted avg   0.900600  0.896059  0.894722      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.47442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.799798  0.905034  0.849168       874\n",
      "        spam   0.844569  0.694915  0.762468       649\n",
      "\n",
      "    accuracy                       0.815496      1523\n",
      "   macro avg   0.822184  0.799975  0.805818      1523\n",
      "weighted avg   0.818876  0.815496  0.812222      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 9\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.34123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.877000  0.964245  0.918555      3468\n",
      "        spam   0.945542  0.821129  0.878955      2622\n",
      "\n",
      "    accuracy                       0.902627      6090\n",
      "   macro avg   0.911271  0.892687  0.898755      6090\n",
      "weighted avg   0.906510  0.902627  0.901506      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.46685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.800620  0.886728  0.841477       874\n",
      "        spam   0.821622  0.702619  0.757475       649\n",
      "\n",
      "    accuracy                       0.808273      1523\n",
      "   macro avg   0.811121  0.794674  0.799476      1523\n",
      "weighted avg   0.809569  0.808273  0.805681      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 10\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.31936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.887174  0.961361  0.922779      3468\n",
      "        spam   0.942539  0.838291  0.887364      2622\n",
      "\n",
      "    accuracy                       0.908374      6090\n",
      "   macro avg   0.914856  0.899826  0.905071      6090\n",
      "weighted avg   0.911011  0.908374  0.907531      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.46111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.796715  0.887872  0.839827       874\n",
      "        spam   0.821494  0.694915  0.752922       649\n",
      "\n",
      "    accuracy                       0.805647      1523\n",
      "   macro avg   0.809104  0.791394  0.796374      1523\n",
      "weighted avg   0.807274  0.805647  0.802794      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 11\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.30050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.892036  0.962514  0.925936      3468\n",
      "        spam   0.944634  0.845919  0.892555      2622\n",
      "\n",
      "    accuracy                       0.912315      6090\n",
      "   macro avg   0.918335  0.904217  0.909246      6090\n",
      "weighted avg   0.914682  0.912315  0.911564      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.45606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.798969  0.886728  0.840564       874\n",
      "        spam   0.820976  0.699538  0.755408       649\n",
      "\n",
      "    accuracy                       0.806960      1523\n",
      "   macro avg   0.809973  0.793133  0.797986      1523\n",
      "weighted avg   0.808347  0.806960  0.804276      1523\n",
      "\n",
      "___________________________________\n",
      "Epoch: 12\n",
      "---------\n",
      "Looked at 0/6090 samples\n",
      "Train loss: 0.28343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.898898  0.963956  0.930291      3468\n",
      "        spam   0.947280  0.856598  0.899660      2622\n",
      "\n",
      "    accuracy                       0.917734      6090\n",
      "   macro avg   0.923089  0.910277  0.914975      6090\n",
      "weighted avg   0.919728  0.917734  0.917103      6090\n",
      "\n",
      "Looked at 0/1523 samples\n",
      "Test loss: 0.45462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.803141  0.877574  0.838710       874\n",
      "        spam   0.811620  0.710324  0.757601       649\n",
      "\n",
      "    accuracy                       0.806303      1523\n",
      "   macro avg   0.807381  0.793949  0.798155      1523\n",
      "weighted avg   0.806754  0.806303  0.804146      1523\n",
      "\n",
      "___________________________________\n",
      "Train time on cpu: 6.306 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Start timer\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 13\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    \n",
    "    # Train the model\n",
    "    train_loss, (train_metrics, train_classification_report)= train_mode(tweet_model, train_loader, criterion, optimizer)\n",
    "    print(f\"Train loss: {train_loss:.5f}\")\n",
    "    # print(f\"Train metrics: {train_metrics}\")\n",
    "    print(train_classification_report)\n",
    "    \n",
    "    # Test/Validate the model\n",
    "    test_loss, (test_metrics,test_classification_report) = test_mode(tweet_model, val_loader, criterion, optimizer)\n",
    "    print(f\"Test loss: {test_loss:.5f}\")\n",
    "    # print(f\"Test metrics: {test_metrics}\")\n",
    "    print(test_classification_report)\n",
    "\n",
    "    print(\"___________________________________\")\n",
    "    \n",
    "# End timer\n",
    "train_time_end_on_cpu = timer()\n",
    "\n",
    "# Calculate total training time\n",
    "total_train_time_model = print_train_time(start=train_time_start_on_cpu, \n",
    "                                           end=train_time_end_on_cpu,\n",
    "                                           device=str(next(tweet_model.parameters()).device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36dcb485-a503-479a-a390-0da859431eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_set(tweet_model, test_loader)\n",
    "y_pred = [int(pred[0]) for pred in y_pred]\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\simple_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b89d82-588d-4ae6-b0d3-cc36fd92c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = train_df['text']\n",
    "y_count = train_df['target']\n",
    "X_test_count = test_df['text']\n",
    "\n",
    "X_train_count, X_val_count, y_train_count, y_val_count = train_test_split(X_count, y_count, test_size=0.2, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train_count)\n",
    "X_val_vec = vectorizer.transform(X_val_count)\n",
    "X_test_vec = vectorizer.transform(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7af70cec-496f-49e2-bfa0-57d5a4880533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030203545633617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.805970  0.864989  0.834437       874\n",
      "        spam   0.798291  0.719569  0.756888       649\n",
      "\n",
      "    accuracy                       0.803020      1523\n",
      "   macro avg   0.802130  0.792279  0.795663      1523\n",
      "weighted avg   0.802698  0.803020  0.801391      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train_count)\n",
    "y_pred = nb_model.predict(X_val_vec)\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'],digits = 6))\n",
    "y_pred = nb_model.predict(X_test_vec)\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\nb_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e180b8f-d3cd-4cfc-ab86-d20753b83790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8010505581089954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.801478  0.868421  0.833608       874\n",
      "        spam   0.800347  0.710324  0.752653       649\n",
      "\n",
      "    accuracy                       0.801051      1523\n",
      "   macro avg   0.800913  0.789372  0.793130      1523\n",
      "weighted avg   0.800996  0.801051  0.799110      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train_count)\n",
    "\n",
    "y_pred = model.predict(X_val_vec)\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'],digits = 6))\n",
    "y_pred = model.predict(X_test_vec)\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\nb_logisticregression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d4b696d-1cbc-4aaf-96b5-eb9a3bb28d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8063033486539725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.785222  0.911899  0.843833       874\n",
      "        spam   0.848425  0.664099  0.745030       649\n",
      "\n",
      "    accuracy                       0.806303      1523\n",
      "   macro avg   0.816823  0.787999  0.794431      1523\n",
      "weighted avg   0.812155  0.806303  0.801730      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf') \n",
    "\n",
    "model.fit(X_train_vec, y_train_count)\n",
    "\n",
    "y_pred = model.predict(X_val_vec)\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'], digits=6))\n",
    "y_pred = model.predict(X_test_vec)\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\svm_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a8c9d6-6779-4f71-abeb-e3cae4175810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:32:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7800393959290873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.761397  0.898169  0.824147       874\n",
      "        spam   0.819106  0.620955  0.706398       649\n",
      "\n",
      "    accuracy                       0.780039      1523\n",
      "   macro avg   0.790251  0.759562  0.765272      1523\n",
      "weighted avg   0.785988  0.780039  0.773970      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,  # Number of boosting rounds (trees)\n",
    "    learning_rate=0.1,  # Step size shrinkage, lower values make the model more conservative\n",
    "    max_depth=6,  # Maximum tree depth for base learners\n",
    "    objective='binary:logistic',  # Since you have a binary classification problem\n",
    "    eval_metric='logloss',  # Evaluation metric, can be 'logloss' or 'error'\n",
    "    use_label_encoder=False  # Disable label encoding for compatibility\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train_vec, y_train_count)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val_vec)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'], digits=6))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Create DataFrame for test predictions\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\xgboost_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9c28d31-8a77-4289-99fb-8fdd963ef5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1807\n",
      "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 668\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Accuracy: 0.7892317793827971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.815279  0.818078  0.816676       874\n",
      "        spam   0.753870  0.750385  0.752124       649\n",
      "\n",
      "    accuracy                       0.789232      1523\n",
      "   macro avg   0.784575  0.784232  0.784400      1523\n",
      "weighted avg   0.789111  0.789232  0.789168      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Convert the training data to float32 or float64\n",
    "X_train_vec = X_train_vec.astype(np.float32)\n",
    "X_val_vec = X_val_vec.astype(np.float32)\n",
    "X_test_vec = X_test_vec.astype(np.float32)\n",
    "\n",
    "# Initialize LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,  # No limit on tree depth\n",
    "    objective='binary',  # For binary classification\n",
    "    class_weight='balanced'  # Automatically handle class imbalance\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train_vec, y_train_count)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val_vec)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'], digits=6))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Create DataFrame for test predictions\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\lightgbm_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bab9f53-2074-4c11-8ff4-ff11278eae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harish-4072\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7307944845699278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham   0.704225  0.915332  0.796020       874\n",
      "        spam   0.808786  0.482280  0.604247       649\n",
      "\n",
      "    accuracy                       0.730794      1523\n",
      "   macro avg   0.756505  0.698806  0.700134      1523\n",
      "weighted avg   0.748782  0.730794  0.714299      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize AdaBoost model with base estimator as a Decision Tree\n",
    "model = AdaBoostClassifier(\n",
    "    n_estimators=100,  # Number of boosting rounds\n",
    "    learning_rate=0.1  # Step size shrinkage\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(X_train_vec, y_train_count)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val_vec)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f'Accuracy: {accuracy_score(y_val_count, y_pred)}')\n",
    "print(classification_report(y_val_count, y_pred, target_names=['ham', 'spam'], digits=6))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Create DataFrame for test predictions\n",
    "output_df = pd.DataFrame({\n",
    "    'id': test_df_id,\n",
    "    'target': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv(r'D:\\Kaggle\\disaster tweets\\adaboost_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266dae6-fcbc-4b2a-91a1-e7ef2c5801fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
